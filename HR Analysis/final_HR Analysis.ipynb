{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b237b398",
   "metadata": {},
   "source": [
    "# HR DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0461c0",
   "metadata": {},
   "source": [
    "**GOALS:** \n",
    "    \n",
    "    1.Data cleansing involving \"removing unnecessary columns\".\n",
    "    2.Giving the columns new names.\n",
    "    3.Eliminating redundant entries.\n",
    "    4.sanitizing specific columns.\n",
    "    5.To eliminate the dataset's NaN values.\n",
    "    6.Look for a few more changes if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d34634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"HR Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5535e1",
   "metadata": {},
   "source": [
    "# **Removing unnecessary columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15414f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber','MaritalStatus']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3acea",
   "metadata": {},
   "source": [
    "# Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a10d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'MothlyIncome': 'MonthlyIncome',\n",
    "    'NumCompaniesWork': 'NumCompaniesWorked',\n",
    "    'RelationSatisfaction': 'RelationshipSatisfaction',\n",
    "    'TrainingTimes': 'TrainingTimesLastYear'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc33691",
   "metadata": {},
   "source": [
    "# Eliminate redundant entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b78697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ad191",
   "metadata": {},
   "source": [
    "# Sanitize specific columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af8950b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].astype(int)\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa17400",
   "metadata": {},
   "source": [
    "# Eliminate NaN values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066afb6",
   "metadata": {},
   "source": [
    "**Option 1:** Drop rows with any NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f550f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7357d",
   "metadata": {},
   "source": [
    "**Option 2:** Fill NaN values with specific values or strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b61ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({\n",
    "    'Age': df['Age'].mean(),\n",
    "    'MonthlyIncome': df['MonthlyIncome'].median(),\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f3f9e",
   "metadata": {},
   "source": [
    "# Additional changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae98ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca3b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsAtCompanyOver10'] = df['YearsAtCompany'].apply(lambda x: 1 if x > 10 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933b25a",
   "metadata": {},
   "source": [
    "**Check final dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f6f41db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Attrition     BusinessTravel  DailyRate              Department  \\\n",
      "0   41          1      Travel_Rarely       1102                   Sales   \n",
      "1   49          0  Travel_Frequently        279  Research & Development   \n",
      "2   37          1      Travel_Rarely       1373  Research & Development   \n",
      "3   33          0  Travel_Frequently       1392  Research & Development   \n",
      "4   27          0      Travel_Rarely        591  Research & Development   \n",
      "\n",
      "   DistanceFromHome  Education EducationField  EnvironmentSatisfaction  \\\n",
      "0                 1          2  Life Sciences                        2   \n",
      "1                 8          1  Life Sciences                        3   \n",
      "2                 2          2          Other                        4   \n",
      "3                 3          4  Life Sciences                        4   \n",
      "4                 2          1        Medical                        1   \n",
      "\n",
      "   Gender  ...  RelationshipSatisfaction  StockOptionLevel  TotalWorkingYears  \\\n",
      "0       0  ...                         1                 0                  8   \n",
      "1       1  ...                         4                 1                 10   \n",
      "2       1  ...                         2                 0                  7   \n",
      "3       0  ...                         3                 0                  8   \n",
      "4       1  ...                         4                 1                  6   \n",
      "\n",
      "  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
      "0                     0                1               6                   4   \n",
      "1                     3                3              10                   7   \n",
      "2                     3                3               0                   0   \n",
      "3                     3                3               8                   7   \n",
      "4                     3                3               2                   2   \n",
      "\n",
      "   YearsSinceLastPromotion YearsWithCurrManager  YearsAtCompanyOver10  \n",
      "0                        0                    5                     0  \n",
      "1                        1                    7                     0  \n",
      "2                        0                    0                     0  \n",
      "3                        3                    0                     0  \n",
      "4                        2                    2                     0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1470 entries, 0 to 1469\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       1470 non-null   int32  \n",
      " 1   Attrition                 1470 non-null   int64  \n",
      " 2   BusinessTravel            1470 non-null   object \n",
      " 3   DailyRate                 1470 non-null   int64  \n",
      " 4   Department                1470 non-null   object \n",
      " 5   DistanceFromHome          1470 non-null   int64  \n",
      " 6   Education                 1470 non-null   int64  \n",
      " 7   EducationField            1470 non-null   object \n",
      " 8   EnvironmentSatisfaction   1470 non-null   int64  \n",
      " 9   Gender                    1470 non-null   int64  \n",
      " 10  HourlyRate                1470 non-null   int64  \n",
      " 11  JobInvolvement            1470 non-null   int64  \n",
      " 12  JobLevel                  1470 non-null   int64  \n",
      " 13  JobRole                   1470 non-null   object \n",
      " 14  JobSatisfaction           1470 non-null   int64  \n",
      " 15  MonthlyIncome             1470 non-null   float64\n",
      " 16  MonthlyRate               1470 non-null   int64  \n",
      " 17  NumCompaniesWorked        1470 non-null   int64  \n",
      " 18  OverTime                  1470 non-null   object \n",
      " 19  PercentSalaryHike         1470 non-null   int64  \n",
      " 20  PerformanceRating         1470 non-null   int64  \n",
      " 21  RelationshipSatisfaction  1470 non-null   int64  \n",
      " 22  StockOptionLevel          1470 non-null   int64  \n",
      " 23  TotalWorkingYears         1470 non-null   int64  \n",
      " 24  TrainingTimesLastYear     1470 non-null   int64  \n",
      " 25  WorkLifeBalance           1470 non-null   int64  \n",
      " 26  YearsAtCompany            1470 non-null   int64  \n",
      " 27  YearsInCurrentRole        1470 non-null   int64  \n",
      " 28  YearsSinceLastPromotion   1470 non-null   int64  \n",
      " 29  YearsWithCurrManager      1470 non-null   int64  \n",
      " 30  YearsAtCompanyOver10      1470 non-null   int64  \n",
      "dtypes: float64(1), int32(1), int64(24), object(5)\n",
      "memory usage: 361.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1a96b",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ff4e0",
   "metadata": {},
   "source": [
    "1.Improved Data Quality:\n",
    "\n",
    "By removing unnecessary columns such as EmployeeCount, Over18, StandardHours, and EmployeeNumber, we streamlined the dataset,   making it more manageable and focused on relevant attributes. This step was crucial in enhancing the overall quality and usability of the data.\n",
    "\n",
    "2.Consistent Data Formatting:\n",
    "\n",
    "Renaming columns with inconsistent or incorrect names, such as MothlyIncome to MonthlyIncome and NumCompaniesWork to NumCompaniesWorked, improved the clarity and readability of the dataset. Consistent naming conventions are essential for effective data analysis and visualization.\n",
    "\n",
    "3.Handling Missing and Duplicate Data:\n",
    "\n",
    "By eliminating duplicate entries and handling NaN values through appropriate imputation techniques, we ensured that the dataset is accurate and reliable. This process is vital in avoiding biases and inaccuracies in the subsequent analysis and modeling stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0d018",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58eb21",
   "metadata": {},
   "source": [
    "1.Regular Data Audits:\n",
    "\n",
    "Implement regular data audits to ensure ongoing data quality and consistency. Periodic reviews can help identify and rectify any discrepancies, missing values, or outdated information, maintaining the dataset's integrity over time.\n",
    "\n",
    "2.Standardize Data Entry Processes:\n",
    "\n",
    "Develop and enforce standardized data entry protocols to minimize errors and inconsistencies. Training employees on these standards and using automated data validation tools can significantly reduce the risk of incorrect data entries.\n",
    "\n",
    "3.Explore Advanced Imputation Techniques:\n",
    "\n",
    "For handling missing values, consider exploring advanced imputation techniques such as K-Nearest Neighbors (KNN) or machine learning-based methods. These techniques can provide more accurate estimates for missing data compared to simple mean or median imputation, especially in complex datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
